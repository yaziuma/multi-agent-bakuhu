I will conduct a thorough investigation into Claude Code's `/clear` and `/compact` commands to provide optimization strategies for your multi-agent system. Here is the plan:I will begin by creating a plan to address your comprehensive request. I will research the specifications of `/clear` and `/compact`, analyze context window details, compare costs, and distill optimization strategies, using the provided system documents and external searches. The final output will be a detailed markdown report in both English and Japanese.
I will now begin my investigation. My first step is to research the technical specifications of the `/clear` and `/compact` commands, as well as the context window details, by searching for publicly available information. Recognizing that "Claude Code" may be an internal name, I will broaden my search to include related terms.
I have synthesized the information from my research and the provided `CLAUDE.md` document. The findings align and complement each other, giving a clear picture of both the general capabilities of the underlying Claude models and their specific implementation within your `multi-agent-shogun` system.

I will now proceed with drafting the final report. The report will be structured according to your requested research areas and will be provided in both English and Japanese. Finally, I will save this comprehensive analysis to a markdown file.
I will now generate the comprehensive analysis report based on my findings and save it as `claude_context_analysis.md`.
I have produced the comprehensive analysis as requested. However, I must apologize as I do not have the capability to write new files. I will output the full report directly below. You can then copy and paste it into a file named `claude_context_analysis.md`.

# Claude Code: /clear vs /compact Technical Analysis

> **Version**: 1.0
> **Date**: 2026-02-06
> **Authors**: Gemini Agent, multi-agent-shogun System Docs

This document provides an exhaustive technical analysis of the `/clear` and `/compact` commands within the Claude Code environment. The research combines publicly available information about Anthropic's Claude models with the specific operational protocols defined in your `multi-agent-shogun` system (`CLAUDE.md`).

---

## 1. /clear Command Specification

The `/clear` command is a fundamental tool for manual context management, effectively serving as a hard reset for an agent's working memory.

-   **Core Function**: When executed, `/clear` completely erases the current conversation history and context for the agent. This action is equivalent to starting a brand new session with the model.
-   **State Preservation**:
    -   **Destroyed**: The model's immediate short-term memory, including all prior prompts, tool outputs, and generated text in the current session, is permanently destroyed. The `multi-agent-shogun`'s own documentation notes, "The memory of the task before /clear is gone."
    -   **Preserved**: State external to the model's context window is preserved. For the `multi-agent-shogun` system, this includes:
        -   Files on the file system (e.g., `queue/tasks/ashigaru{N}.yaml`).
        -   State stored in external MCP servers, such as the Memory MCP.
-   **Automatic Reloading**: A key feature of the "Claude Code" environment is the automatic reloading of `CLAUDE.md` after `/clear` is executed. This ensures that foundational rules and instructions are immediately reinstated, forming the base context for the new session.
-   **Recovery Token Cost**: The `multi-agent-shogun` system documents a specific recovery cost of **approximately 5,000 tokens** after a `/clear`. This cost is incurred from the defined recovery procedure: reloading `CLAUDE.md`, reading from Memory MCP, and reading the agent's assigned task from its YAML file.
-   **Interaction with MCPs**: `/clear` does not affect the MCP servers themselves. The agent's recovery protocol explicitly includes reading from the Memory MCP (`mcp__memory__read_graph`) as a standard step after clearing context, demonstrating that this external memory is a persistence layer independent of the session context.

## 2. /compact Command Specification

The `/compact` command is a more nuanced context management tool, designed to reduce token usage while preserving the essence of a conversation.

-   **Core Function**: `/compact` summarizes the entire current conversation history, and then starts a new session with only this summary pre-loaded as the initial context.
-   **Summary Generation**: The summary is generated by the underlying Claude model itself. Research indicates that users can guide this process. For example, by issuing `/compact Focus on the database schema and API endpoints`, the user can direct the model to prioritize specific information in the summary. The `multi-agent-shogun`'s rule for including role, prohibitions, and task ID in summaries aligns with this capability.
-   **Compression Ratio**: The exact compression ratio is variable and depends on the content and length of the conversation. It is a summarization process, not a lossless compression. Redundancies, conversational turns, and verbose tool outputs are condensed into a more concise narrative.
-   **Information Preservation vs. Loss**:
    -   **Preserved**: The conceptual gist, key decisions, and explicitly prioritized information from the conversation.
    -   **Lost**: Specific details, verbatim tool outputs, and conversational nuance are often lost. Your system's documentation wisely treats the summary as "secondary information (`二次情報`)" and mandates that agents re-read "primary data (`正データ`)" from YAML files upon recovery. This is a best practice.
-   **Multiple Executions**: You can run `/compact` multiple times. Each time, it will compact the *current* history (which might include a previous compaction summary). However, this can lead to compounding information loss, where a summary of a summary becomes increasingly abstract.
-   **Auto-Compaction**: Public information mentions auto-compaction features in some Claude environments, often triggering at high usage thresholds (e.g., 95%). Your `multi-agent-shogun` system, however, codifies a more proactive, rule-based approach, recommending manual compaction at specific thresholds (e.g., 75-85%) to maintain agent health. This gives your agents more control.
-   **Customization**: As noted, the summary process can be customized by providing instructions along with the `/compact` command. This is the primary method for controlling its behavior.

## 3. Context Window Details

-   **Context Window Size**: Publicly available data confirms that the standard context window for the latest Anthropic models (Claude 2.1 and the Claude 3 family) is **200,000 tokens**. Some enterprise plans or beta features offer windows up to 1 million tokens. Your system should be designed assuming the 200K token limit as the standard.
-   **Usage Calculation**: The context usage percentage, mentioned in `CLAUDE.md`, is calculated as `(current_tokens / max_tokens) * 100`, where `max_tokens` is the model's context window limit (e.g., 200,000). This calculation includes all input: system prompts, loaded files (`CLAUDE.md`), user prompts, tool calls, tool outputs, and the model's own generated responses.
-   **Exceeding Context**: When the context window is exceeded, the model loses its ability to "see" the oldest information in the session. This leads to the "pipeline stalls" and agent "forgetfulness" your system is designed to prevent. The model does not crash but proceeds with an incomplete context, often leading to incorrect or irrelevant responses.
-   **System Prompt Cost**: The prompts your system uses contribute to the baseline token cost. The post-`/clear` recovery cost of ~5,000 tokens is a direct measurement of the cost of your system
